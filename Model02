//학습된 모델 저장하기

# 0. 사용할 패키지 불러오기
from keras.utils import np_utils
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Activation
import numpy as np
from numpy import argmax

# 1. 데이터셋 생성하기

# 훈련셋과 시험셋 불러오기
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 데이터셋 전처리
x_train = x_train.reshape(60000, 784).astype('float32') / 255.0
x_test = x_test.reshape(10000, 784).astype('float32') / 255.0

# 원핫인코딩 (one-hot encoding) 처리
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

# 훈련셋과 검증셋 분리
x_val = x_train[:42000] # 훈련셋의 30%를 검증셋으로 사용
x_train = x_train[42000:]
y_val = y_train[:42000] # 훈련셋의 30%를 검증셋으로 사용
y_train = y_train[42000:]

# 2. 모델 구성하기
model = Sequential()
model.add(Dense(units=64, input_dim=28*28, activation='relu'))
model.add(Dense(units=10, activation='softmax'))

# 3. 모델 학습과정 설정하기
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# 4. 모델 학습시키기
model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))

# 5. 모델 평가하기
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)
print('')
print('loss_and_metrics : ' + str(loss_and_metrics))

# 6. 모델 저장하기
from keras.models import load_model
model.save('mnist_mlp_model.h5')

==================================================================
실행결과 :
Epoch 1/5
563/563 [==============================] - 2s 2ms/step - loss: 1.1651 - accuracy: 0.7067 - val_loss: 0.6628 - val_accuracy: 0.8371
Epoch 2/5
563/563 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.8693 - val_loss: 0.4778 - val_accuracy: 0.8720
Epoch 3/5
563/563 [==============================] - 1s 2ms/step - loss: 0.4138 - accuracy: 0.8863 - val_loss: 0.4159 - val_accuracy: 0.8855
Epoch 4/5
563/563 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8982 - val_loss: 0.3841 - val_accuracy: 0.8929
Epoch 5/5
563/563 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.9043 - val_loss: 0.3588 - val_accuracy: 0.8994
<keras.callbacks.History at 0x1588d891730>
313/313 [==============================] - 0s 716us/step - loss: 0.3317 - accuracy: 0.9090

loss_and_metrics : [0.3317118287086487, 0.9089999794960022]
